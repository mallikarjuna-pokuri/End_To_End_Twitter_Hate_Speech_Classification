{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.utils.common import get_size\n",
    "from src.entity.config_entity import DataTransformationConfig\n",
    "from pathlib import Path\n",
    "from logger import logger\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from src.utils.common import transformed_text,tokenized_text\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import joblib\n",
    "import keras\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "    def transform_data(self):\n",
    "        try:\n",
    "            print(\"started\")\n",
    "            nltk.download('stopwords')\n",
    "            stop_words = stopwords.words('english')\n",
    "            with open(os.path.join(self.config.root_dir,\"stopwords.txt\"),\"w\"):\n",
    "                f.write(stop_words)\n",
    "            df = pd.read_csv(self.config.local_data_file)\n",
    "            logger(f\"Twitter data read successfully of shape {df.shape}\")\n",
    "            df['processed_text'] = df.tweet.apply(lambda x :transformed_text(x))\n",
    "            logger(\"Removed stop words and punctuations\")\n",
    "            tokenizer = Tokenizer()\n",
    "            tokenizer.fit_on_texts(df.processed_text)\n",
    "            with open(os.path.join(self.config.root_dir,\"tokenizer.pkl\"),\"wb\") as f:\n",
    "                joblib.dump(tokenizer,f)\n",
    "            vocab_size = len(tokenizer.word_index)+1\n",
    "            logger(f\"Vocabulary size of tokenizer is {vocab_size}\")\n",
    "            tokenized_text = tokenizer.texts_to_sequences(df.processed_text)\n",
    "            max_len = max(len(seq) for seq in tokenized_text)\n",
    "            padded_tokenized_text = pad_sequences(tokenized_text, maxlen = max_len,padding = 'post')\n",
    "            labels = to_categorical(df['class'], num_classes=3)\n",
    "            df2 = pd.DataFrame([padded_tokenized_text,labels])\n",
    "            train,test= train_test_split(df2)\n",
    "            train.to_csv(os.path.join(self.config.root_dir,\"train.csv\"),index = False,Header = False)\n",
    "            test.to_csv(os.path.join(self.config.root_dir,\"test.csv\"),index = False,Header = False)\n",
    "        except Exception as e:\n",
    "            raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\malli\\Desktop\\ML\\End_To_End_Twitter_Hate_Speech_Classification\\research\\trials.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/malli/Desktop/ML/End_To_End_Twitter_Hate_Speech_Classification/research/trials.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m logger(\u001b[39m\"\u001b[39;49m\u001b[39mHI everyone\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "logger(\"HI everyone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\malli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\malli\\Desktop\\ML\\End_To_End_Twitter_Hate_Speech_Classification\\src\\components\\data_Transformation.py:24\u001b[0m, in \u001b[0;36mDataTransformation.transform_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     23\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mlocal_data_file)\n\u001b[1;32m---> 24\u001b[0m logger(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTwitter data read successfully of shape \u001b[39;49m\u001b[39m{\u001b[39;49;00mdf\u001b[39m.\u001b[39;49mshape\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     25\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: transformed_text(x))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\malli\\Desktop\\ML\\End_To_End_Twitter_Hate_Speech_Classification\\research\\trials.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/malli/Desktop/ML/End_To_End_Twitter_Hate_Speech_Classification/research/trials.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/malli/Desktop/ML/End_To_End_Twitter_Hate_Speech_Classification/research/trials.ipynb#W2sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     logging\u001b[39m.\u001b[39mexception(e)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/malli/Desktop/ML/End_To_End_Twitter_Hate_Speech_Classification/research/trials.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[1;32mc:\\Users\\malli\\Desktop\\ML\\End_To_End_Twitter_Hate_Speech_Classification\\research\\trials.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/malli/Desktop/ML/End_To_End_Twitter_Hate_Speech_Classification/research/trials.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m>>>>>> stage \u001b[39m\u001b[39m{\u001b[39;00mSTAGE_NAME\u001b[39m}\u001b[39;00m\u001b[39m started <<<<<<\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/malli/Desktop/ML/End_To_End_Twitter_Hate_Speech_Classification/research/trials.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     obj \u001b[39m=\u001b[39m DataTransformationPipeline()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/malli/Desktop/ML/End_To_End_Twitter_Hate_Speech_Classification/research/trials.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     obj\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/malli/Desktop/ML/End_To_End_Twitter_Hate_Speech_Classification/research/trials.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m>>>>>> stage \u001b[39m\u001b[39m{\u001b[39;00mSTAGE_NAME\u001b[39m}\u001b[39;00m\u001b[39m completed <<<<<<\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mx==========x\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/malli/Desktop/ML/End_To_End_Twitter_Hate_Speech_Classification/research/trials.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;32mc:\\Users\\malli\\Desktop\\ML\\End_To_End_Twitter_Hate_Speech_Classification\\research\\trials.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/malli/Desktop/ML/End_To_End_Twitter_Hate_Speech_Classification/research/trials.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m DataTransformationConfig \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget_data_transformation_config()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/malli/Desktop/ML/End_To_End_Twitter_Hate_Speech_Classification/research/trials.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m data_transformation \u001b[39m=\u001b[39m DataTransformation(config \u001b[39m=\u001b[39m DataTransformationConfig)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/malli/Desktop/ML/End_To_End_Twitter_Hate_Speech_Classification/research/trials.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m data_transformation\u001b[39m.\u001b[39;49mtransform_data()\n",
      "File \u001b[1;32mc:\\Users\\malli\\Desktop\\ML\\End_To_End_Twitter_Hate_Speech_Classification\\src\\components\\data_Transformation.py:47\u001b[0m, in \u001b[0;36mDataTransformation.transform_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m     test\u001b[39m.\u001b[39mto_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mroot_dir,\u001b[39m\"\u001b[39m\u001b[39mtest.csv\u001b[39m\u001b[39m\"\u001b[39m),index \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,Header \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m---> 47\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m\n",
      "\u001b[1;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.config.configuration import ConfigurationManager\n",
    "from src.components.data_Transformation import DataTransformation\n",
    "from logger import logging\n",
    "\n",
    "\n",
    "class DataTransformationPipeline:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    def run(self):\n",
    "        config = ConfigurationManager()\n",
    "        DataTransformationConfig = config.get_data_transformation_config()\n",
    "        data_transformation = DataTransformation(config = DataTransformationConfig)\n",
    "        data_transformation.transform_data()\n",
    "\n",
    "  \n",
    "STAGE_NAME = \"Data Ingestion stage\"\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        logging.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\")\n",
    "        obj = DataTransformationPipeline()\n",
    "        obj.run()\n",
    "        logging.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\n",
    "    except Exception as e:\n",
    "        logging.exception(e)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\malli\\Desktop\\ML\\End_To_End_Twitter_Hate_Speech_Classification\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\malli\\\\Desktop\\\\ML\\\\End_To_End_Twitter_Hate_Speech_Classification'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n",
    "%cd ..\n",
    "%pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
